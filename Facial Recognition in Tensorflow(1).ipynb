{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from builtins import range\n",
    "# Note: you may need to update your version of future\n",
    "# sudo pip install -U future\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from util import getImageData, error_rate, init_weight_and_bias, y2indicator\n",
    "from ann_tf import HiddenLayer\n",
    "\n",
    "# differences from Theano:\n",
    "# image dimensions are expected to be: N x width x height x color\n",
    "# filter shapes are expected to be: filter width x filter height x input feature maps x output feature maps\n",
    "\n",
    "\n",
    "def init_filter(shape, poolsz):\n",
    "    w = np.random.randn(*shape) / np.sqrt(np.prod(shape[:-1]) + shape[-1]*np.prod(shape[:-2] / np.prod(poolsz)))\n",
    "    return w.astype(np.float32)\n",
    "\n",
    "\n",
    "class ConvPoolLayer(object):\n",
    "    def __init__(self, mi, mo, fw=5, fh=5, poolsz=(2, 2)):\n",
    "        # mi = input feature map size\n",
    "        # mo = output feature map size\n",
    "        sz = (fw, fh, mi, mo)\n",
    "        W0 = init_filter(sz, poolsz)\n",
    "        self.W = tf.Variable(W0)\n",
    "        b0 = np.zeros(mo, dtype=np.float32)\n",
    "        self.b = tf.Variable(b0)\n",
    "        self.poolsz = poolsz\n",
    "        self.params = [self.W, self.b]\n",
    "\n",
    "    def forward(self, X):\n",
    "        conv_out = tf.nn.conv2d(X, self.W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        conv_out = tf.nn.bias_add(conv_out, self.b)\n",
    "        p1, p2 = self.poolsz\n",
    "        pool_out = tf.nn.max_pool(\n",
    "            conv_out,\n",
    "            ksize=[1, p1, p2, 1],\n",
    "            strides=[1, p1, p2, 1],\n",
    "            padding='SAME'\n",
    "        )\n",
    "        return tf.tanh(pool_out)\n",
    "\n",
    "\n",
    "class CNN(object):\n",
    "    def __init__(self, convpool_layer_sizes, hidden_layer_sizes):\n",
    "        self.convpool_layer_sizes = convpool_layer_sizes\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "\n",
    "    def fit(self, X, Y, lr=10e-4, mu=0.99, reg=10e-4, decay=0.99999, eps=10e-3, batch_sz=30, epochs=3, show_fig=True):\n",
    "        lr = np.float32(lr)\n",
    "        mu = np.float32(mu)\n",
    "        reg = np.float32(reg)\n",
    "        decay = np.float32(decay)\n",
    "        eps = np.float32(eps)\n",
    "        K = len(set(Y))\n",
    "\n",
    "        # make a validation set\n",
    "        X, Y = shuffle(X, Y)\n",
    "        X = X.astype(np.float32)\n",
    "        Y = y2indicator(Y).astype(np.float32)\n",
    "\n",
    "        Xvalid, Yvalid = X[-1000:], Y[-1000:]\n",
    "        X, Y = X[:-1000], Y[:-1000]\n",
    "        Yvalid_flat = np.argmax(Yvalid, axis=1) # for calculating error rate\n",
    "\n",
    "        # initialize convpool layers\n",
    "        N, width, height, c = X.shape\n",
    "        mi = c\n",
    "        outw = width\n",
    "        outh = height\n",
    "        self.convpool_layers = []\n",
    "        for mo, fw, fh in self.convpool_layer_sizes:\n",
    "            layer = ConvPoolLayer(mi, mo, fw, fh)\n",
    "            self.convpool_layers.append(layer)\n",
    "            outw = outw // 2\n",
    "            outh = outh // 2\n",
    "            mi = mo\n",
    "\n",
    "        # initialize mlp layers\n",
    "        self.hidden_layers = []\n",
    "        M1 = self.convpool_layer_sizes[-1][0]*outw*outh # size must be same as output of last convpool layer\n",
    "        count = 0\n",
    "        for M2 in self.hidden_layer_sizes:\n",
    "            h = HiddenLayer(M1, M2, count)\n",
    "            self.hidden_layers.append(h)\n",
    "            M1 = M2\n",
    "            count += 1\n",
    "\n",
    "        # logistic regression layer\n",
    "        W, b = init_weight_and_bias(M1, K)\n",
    "        self.W = tf.Variable(W, 'W_logreg')\n",
    "        self.b = tf.Variable(b, 'b_logreg')\n",
    "\n",
    "        # collect params for later use\n",
    "        self.params = [self.W, self.b]\n",
    "        for h in self.convpool_layers:\n",
    "            self.params += h.params\n",
    "        for h in self.hidden_layers:\n",
    "            self.params += h.params\n",
    "\n",
    "        # set up tensorflow functions and variables\n",
    "        tfX = tf.placeholder(tf.float32, shape=(None, width, height, c), name='X')\n",
    "        tfY = tf.placeholder(tf.float32, shape=(None, K), name='Y')\n",
    "        act = self.forward(tfX)\n",
    "\n",
    "        rcost = reg*sum([tf.nn.l2_loss(p) for p in self.params])\n",
    "        cost = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits(\n",
    "                logits=act,\n",
    "                labels=tfY\n",
    "            )\n",
    "        ) + rcost\n",
    "        prediction = self.predict(tfX)\n",
    "\n",
    "        train_op = tf.train.RMSPropOptimizer(lr, decay=decay, momentum=mu).minimize(cost)\n",
    "\n",
    "        n_batches = N // batch_sz\n",
    "        costs = []\n",
    "        init = tf.global_variables_initializer()\n",
    "        with tf.Session() as session:\n",
    "            session.run(init)\n",
    "            for i in range(epochs):\n",
    "                X, Y = shuffle(X, Y)\n",
    "                for j in range(n_batches):\n",
    "                    Xbatch = X[j*batch_sz:(j*batch_sz+batch_sz)]\n",
    "                    Ybatch = Y[j*batch_sz:(j*batch_sz+batch_sz)]\n",
    "\n",
    "                    session.run(train_op, feed_dict={tfX: Xbatch, tfY: Ybatch})\n",
    "\n",
    "                    if j % 20 == 0:\n",
    "                        c = session.run(cost, feed_dict={tfX: Xvalid, tfY: Yvalid})\n",
    "                        costs.append(c)\n",
    "\n",
    "                        p = session.run(prediction, feed_dict={tfX: Xvalid, tfY: Yvalid})\n",
    "                        e = error_rate(Yvalid_flat, p)\n",
    "                        print(\"i:\", i, \"j:\", j, \"nb:\", n_batches, \"cost:\", c, \"error rate:\", e)\n",
    "\n",
    "        if show_fig:\n",
    "            plt.plot(costs)\n",
    "            plt.show()\n",
    "\n",
    "    def forward(self, X):\n",
    "        Z = X\n",
    "        for c in self.convpool_layers:\n",
    "            Z = c.forward(Z)\n",
    "        Z_shape = Z.get_shape().as_list()\n",
    "        Z = tf.reshape(Z, [-1, np.prod(Z_shape[1:])])\n",
    "        for h in self.hidden_layers:\n",
    "            Z = h.forward(Z)\n",
    "        return tf.matmul(Z, self.W) + self.b\n",
    "\n",
    "    def predict(self, X):\n",
    "        pY = self.forward(X)\n",
    "        return tf.argmax(pY, 1)\n",
    "\n",
    "\n",
    "def main():\n",
    "    X, Y = getImageData()\n",
    "\n",
    "    # reshape X for tf: N x w x h x c\n",
    "    X = X.transpose((0, 2, 3, 1))\n",
    "    print(\"X.shape:\", X.shape)\n",
    "\n",
    "    model = CNN(\n",
    "        convpool_layer_sizes=[(20, 5, 5), (20, 5, 5)],\n",
    "        hidden_layer_sizes=[500, 300],\n",
    "    )\n",
    "    model.fit(X, Y)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
