{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib # matplotlib.pyplot.show('hold')\n",
    "import os\n",
    "\n",
    "images = []\n",
    "\n",
    "for file in os.listdir('../imgs/Extracted/'):\n",
    "    img = cv2.imread(os.path.join('../imgs/Extracted', file), 0)\n",
    "    if img is not None:\n",
    "        images.append((img, file[0:3]))\n",
    "\n",
    "\n",
    "labels = [i[1] for i in images]\n",
    "images = [i[0] for i in images]\n",
    "## append whitespace after finding the max size then resize\n",
    "max_x, max_y = max([i.shape for i in images])\n",
    "\n",
    "max_x = max([i.shape[0] for i in images])\n",
    "max_y = max([i.shape[1] for i in images])\n",
    "\n",
    "scaled_images = []\n",
    "\n",
    "for i in images:\n",
    "    top, bottom, left, right = max_x - i.shape[0], 0, int(np.floor((max_y - i.shape[1]) / 2.0)), int(np.ceil((max_y - i.shape[1]) / 2.0))\n",
    "    scaled_images.append(cv2.copyMakeBorder(i, top, bottom, left, right, borderType=cv2.BORDER_CONSTANT, value=(255, 255, 255, 255)))\n",
    "    \n",
    "    \n",
    "scaled_images = [cv2.resize(i, (200, 200)) for i in scaled_images]\n",
    "scaled_imagesP = [i.flatten() for i in scaled_images]\n",
    "\n",
    "all([len(i) == (200 * 200) for i in scaled_imagesP])\n",
    "\n",
    "plt.imshow(scaled_images[0], cmap='gray')\n",
    "plt.imshow(scaled_images[84], cmap='gray')\n",
    "plt.imshow(scaled_images[1024], cmap='gray')\n",
    "\n",
    "[i.shape[0] for i in images].index(max_x)\n",
    "\n",
    "plt.imshow(scaled_images[405], cmap='gray')\n",
    "plt.imshow(scaled_images[2504], cmap='gray')\n",
    "\n",
    "kek = sum(images)\n",
    "kek = kek / len(images)\n",
    "\n",
    "plt.imshow(kek, cmap='gray')\n",
    "\n",
    "kek = np.ndarray(images)\n",
    "kek = kek.astype(\"double\")\n",
    "\n",
    "kek + kek\n",
    "\n",
    "images[0].dtype\n",
    "\n",
    "kek = [i.astype(\"double\") for i in scaled_images]\n",
    "kek = sum(kek)\n",
    "kek = kek / len(images)\n",
    "\n",
    "plt.imshow(kek, cmap='gray')\n",
    "\n",
    "\n",
    "### average faces\n",
    "scaled_images = [i.astype(\"double\") for i in scaled_images]\n",
    "\n",
    "def plotAvgFace(league):\n",
    "    mat = sum([scaled_images[i] for i,x in enumerate(labels) if x == league])\n",
    "    mat = mat / len([i for i in labels if i == league])\n",
    "    plt.imshow(mat, cmap='gray')\n",
    "    \n",
    "\n",
    "nhl = sum([scaled_images[i] for i,x in enumerate(labels) if x == 'nhl'])\n",
    "nhl = nhl / len([i for i in labels if i == 'nhl'])\n",
    "\n",
    "plt.imshow(nhl, cmap='gray')\n",
    "\n",
    "plotAvgFace(\"nhl\")\n",
    "plotAvgFace(\"nfl\")\n",
    "plotAvgFace(\"nba\")\n",
    "\n",
    "## basic keras model \n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "train = np.vstack(scaled_imagesP)\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(labels)\n",
    "encoded_lab = encoder.transform(labels)\n",
    "\n",
    "labs = keras.utils.np_utils.to_categorical(encoded_lab, 3)\n",
    "\n",
    "train = train.astype(\"float32\")\n",
    "train /= 255\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1200, activation='relu', input_shape=(40000, )))\n",
    "model.add(Dropout(0.02))\n",
    "model.add(Dense(2400, activation='tanh'))\n",
    "model.add(Dropout(0.02))\n",
    "model.add(Dense(2400, activation='sigmoid'))\n",
    "model.add(Dropout(0.02))\n",
    "model.add(Dense(2400, activation='relu'))\n",
    "model.add(Dropout(0.02))\n",
    "model.add(Dense(512, activation='tanh'))\n",
    "model.add(Dropout(0.02))\n",
    "model.add(Dense(2400, activation='tanh'))\n",
    "model.add(Dropout(0.02))\n",
    "model.add(Dense(2400, activation='sigmoid'))\n",
    "model.add(Dropout(0.02))\n",
    "model.add(Dense(2400, activation='relu'))\n",
    "model.add(Dropout(0.02))\n",
    "model.add(Dense(512, activation='tanh'))\n",
    "model.add(Dropout(0.02))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(train, labs, batch_size=10, nb_epoch=10, verbose=1, class_weight='auto')\n",
    "\n",
    "out = model.predict(train)\n",
    "\n",
    "out = [i.tolist().index(max(i)) for i in out]\n",
    "\n",
    "np.mean(out)\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "X_train.shape\n",
    "\n",
    "scaled_images = []\n",
    "\n",
    "for i in images:\n",
    "    top, bottom, left, right = max_x - i.shape[0], 0, int(np.floor((max_y - i.shape[1]) / 2.0)), int(np.ceil((max_y - i.shape[1]) / 2.0))\n",
    "    scaled_images.append(cv2.copyMakeBorder(i, top, bottom, left, right, borderType=cv2.BORDER_CONSTANT, value=(255, 255, 255, 255)))\n",
    "    \n",
    "    \n",
    "scaled_images = [cv2.resize(i, (28, 28)) for i in scaled_images]\n",
    "scaled_images = [cv2.resize(i, (28, 28)) for i in images]\n",
    "\n",
    "images_array = np.dstack(scaled_images)\n",
    "images_array = np.rollaxis(images_array, -1)\n",
    "\n",
    "images_array.shape\n",
    "\n",
    "plt.imshow(images_array[0], cmap='gray')\n",
    "\n",
    "\n",
    "# Simple CNN model for CIFAR-10\n",
    "import numpy\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "images_array = np.expand_dims(images_array, 4)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(12, 2, 2, input_shape=(28, 28, 1), activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Convolution2D(12, 2, 2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(20, 3, 3, activation='relu'))\n",
    "model.add(Convolution2D(20, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Convolution2D(12, 2, 2, activation='relu'))\n",
    "model.add(Convolution2D(20, 2, 2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', W_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "# Compile model\n",
    "epochs = 25\n",
    "lrate = 0.01\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "history = model.fit(images_array, labs, batch_size=20, nb_epoch=1000, verbose=1, class_weight='auto')\n",
    "\n",
    "out = model.predict(images_array)\n",
    "\n",
    "out\n",
    "\n",
    "out2 = [i.tolist().index(max(i)) for i in out]\n",
    "\n",
    "np.mean(out2)\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "log_loss(labs, out)\n",
    "\n",
    "losses = [-(sum(np.log(x) * y)) for x,y in zip(out, labs)]\n",
    "losses.index(max(losses))\n",
    "\n",
    "plt.imshow(scaled_images[2511], cmap='gray')  \n",
    "\n",
    "out[2511]\n",
    "labs[2511]\n",
    "labels[2511]\n",
    "\n",
    "worst_to_best = np.flipud(np.argsort(losses))\n",
    "worst_to_best.tolist().index(2511)\n",
    "\n",
    "plt.imshow(scaled_images[worst_to_best[0]], cmap='gray')\n",
    "out[worst_to_best[0]]\n",
    "labs[worst_to_best[0]]\n",
    "labels[worst_to_best[0]]\n",
    "\n",
    "plt.imshow(scaled_images[worst_to_best[-1]], cmap='gray')\n",
    "out[worst_to_best[-1]]\n",
    "labs[worst_to_best[-1]]\n",
    "labels[worst_to_best[-1]]\n",
    "\n",
    "plt.imshow(scaled_images[worst_to_best[14]], cmap='gray')\n",
    "out[worst_to_best[14]]\n",
    "labs[worst_to_best[14]]\n",
    "labels[worst_to_best[14]]\n",
    "\n",
    "def plotFace(idx):\n",
    "    plt.imshow(scaled_images[worst_to_best[idx]], cmap='gray')\n",
    "    print 'predictions are', out[worst_to_best[idx]]\n",
    "    print 'labels are', labs[worst_to_best[idx]]\n",
    "    print 'sport is', labels[worst_to_best[idx]]\n",
    "    \n",
    "\n",
    "plotFace(13)\n",
    "plotFace(14)\n",
    "plotFace(15)    \n",
    "plotFace(16)\n",
    "plotFace(17)\n",
    "plotFace(18)\n",
    "plotFace(19)\n",
    "plotFace(1600)\n",
    "plotFace(2000)\n",
    "\n",
    "accuracies = history.history.get('acc')\n",
    "epochs = history.epoch\n",
    "\n",
    "plt.plot(epochs, accuracies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
