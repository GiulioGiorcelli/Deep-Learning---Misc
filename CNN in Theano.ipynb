{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://deeplearningcourses.com/c/deep-learning-convolutional-neural-networks-theano-tensorflow\n",
    "# https://udemy.com/deep-learning-convolutional-neural-networks-theano-tensorflow\n",
    "\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from theano.tensor.nnet import conv2d\n",
    "from theano.tensor.signal import downsample\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def error_rate(p, t):\n",
    "    return np.mean(p != t)\n",
    "\n",
    "\n",
    "def relu(a):\n",
    "    return a * (a > 0)\n",
    "\n",
    "\n",
    "def y2indicator(y):\n",
    "    N = len(y)\n",
    "    ind = np.zeros((N, 10))\n",
    "    for i in xrange(N):\n",
    "        ind[i, y[i]] = 1\n",
    "    return ind\n",
    "\n",
    "\n",
    "def convpool(X, W, b, poolsize=(2, 2)):\n",
    "    conv_out = conv2d(input=X, filters=W)\n",
    "\n",
    "    # downsample each feature map individually, using maxpooling\n",
    "    pooled_out = downsample.max_pool_2d(\n",
    "        input=conv_out,\n",
    "        ds=poolsize,\n",
    "        ignore_border=True\n",
    "    )\n",
    "\n",
    "    # add the bias term. Since the bias is a vector (1D array), we first\n",
    "    # reshape it to a tensor of shape (1, n_filters, 1, 1). Each bias will\n",
    "    # thus be broadcasted across mini-batches and feature map\n",
    "    # width & height\n",
    "    # return T.tanh(pooled_out + b.dimshuffle('x', 0, 'x', 'x'))\n",
    "    return relu(pooled_out + b.dimshuffle('x', 0, 'x', 'x'))\n",
    "\n",
    "\n",
    "def init_filter(shape, poolsz):\n",
    "    w = np.random.randn(*shape) / np.sqrt(np.prod(shape[1:]) + shape[0]*np.prod(shape[2:] / np.prod(poolsz)))\n",
    "    return w.astype(np.float32)\n",
    "\n",
    "\n",
    "def rearrange(X):\n",
    "    # input is (32, 32, 3, N)\n",
    "    # output is (N, 3, 32, 32)\n",
    "    N = X.shape[-1]\n",
    "    out = np.zeros((N, 3, 32, 32), dtype=np.float32)\n",
    "    for i in xrange(N):\n",
    "        for j in xrange(3):\n",
    "            out[i, j, :, :] = X[:, :, j, i]\n",
    "    return out / 255\n",
    "\n",
    "\n",
    "def main():\n",
    "    # step 1: load the data, transform as needed\n",
    "    train = loadmat('../large_files/train_32x32.mat')\n",
    "    test  = loadmat('../large_files/test_32x32.mat')\n",
    "\n",
    "    # Need to scale! don't leave as 0..255\n",
    "    # Y is a N x 1 matrix with values 1..10 (MATLAB indexes by 1)\n",
    "    # So flatten it and make it 0..9\n",
    "    # Also need indicator matrix for cost calculation\n",
    "    Xtrain = rearrange(train['X'])\n",
    "    Ytrain = train['y'].flatten() - 1\n",
    "    del train\n",
    "    Xtrain, Ytrain = shuffle(Xtrain, Ytrain)\n",
    "    Ytrain_ind = y2indicator(Ytrain)\n",
    "\n",
    "    Xtest  = rearrange(test['X'])\n",
    "    Ytest  = test['y'].flatten() - 1\n",
    "    del test\n",
    "    Ytest_ind  = y2indicator(Ytest)\n",
    "\n",
    "\n",
    "    max_iter = 8\n",
    "    print_period = 10\n",
    "\n",
    "    lr = np.float32(0.00001)\n",
    "    reg = np.float32(0.01)\n",
    "    mu = np.float32(0.99)\n",
    "\n",
    "    N = Xtrain.shape[0]\n",
    "    batch_sz = 500\n",
    "    n_batches = N / batch_sz\n",
    "\n",
    "    M = 500\n",
    "    K = 10\n",
    "    poolsz = (2, 2)\n",
    "\n",
    "    # after conv will be of dimension 32 - 5 + 1 = 28\n",
    "    # after downsample 28 / 2 = 14\n",
    "    W1_shape = (20, 3, 5, 5) # (num_feature_maps, num_color_channels, filter_width, filter_height)\n",
    "    W1_init = init_filter(W1_shape, poolsz)\n",
    "    b1_init = np.zeros(W1_shape[0], dtype=np.float32) # one bias per output feature map\n",
    "\n",
    "    # after conv will be of dimension 14 - 5 + 1 = 10\n",
    "    # after downsample 10 / 2 = 5\n",
    "    W2_shape = (50, 20, 5, 5) # (num_feature_maps, old_num_feature_maps, filter_width, filter_height)\n",
    "    W2_init = init_filter(W2_shape, poolsz)\n",
    "    b2_init = np.zeros(W2_shape[0], dtype=np.float32)\n",
    "\n",
    "    # vanilla ANN weights\n",
    "    W3_init = np.random.randn(W2_shape[0]*5*5, M) / np.sqrt(W2_shape[0]*5*5 + M)\n",
    "    b3_init = np.zeros(M, dtype=np.float32)\n",
    "    W4_init = np.random.randn(M, K) / np.sqrt(M + K)\n",
    "    b4_init = np.zeros(K, dtype=np.float32)\n",
    "\n",
    "\n",
    "    # step 2: define theano variables and expressions\n",
    "    X = T.tensor4('X', dtype='float32')\n",
    "    Y = T.matrix('T')\n",
    "    W1 = theano.shared(W1_init, 'W1')\n",
    "    b1 = theano.shared(b1_init, 'b1')\n",
    "    W2 = theano.shared(W2_init, 'W2')\n",
    "    b2 = theano.shared(b2_init, 'b2')\n",
    "    W3 = theano.shared(W3_init.astype(np.float32), 'W3')\n",
    "    b3 = theano.shared(b3_init, 'b3')\n",
    "    W4 = theano.shared(W4_init.astype(np.float32), 'W4')\n",
    "    b4 = theano.shared(b4_init, 'b4')\n",
    "\n",
    "    # momentum changes\n",
    "    dW1 = theano.shared(np.zeros(W1_init.shape, dtype=np.float32), 'dW1')\n",
    "    db1 = theano.shared(np.zeros(b1_init.shape, dtype=np.float32), 'db1')\n",
    "    dW2 = theano.shared(np.zeros(W2_init.shape, dtype=np.float32), 'dW2')\n",
    "    db2 = theano.shared(np.zeros(b2_init.shape, dtype=np.float32), 'db2')\n",
    "    dW3 = theano.shared(np.zeros(W3_init.shape, dtype=np.float32), 'dW3')\n",
    "    db3 = theano.shared(np.zeros(b3_init.shape, dtype=np.float32), 'db3')\n",
    "    dW4 = theano.shared(np.zeros(W4_init.shape, dtype=np.float32), 'dW4')\n",
    "    db4 = theano.shared(np.zeros(b4_init.shape, dtype=np.float32), 'db4')\n",
    "\n",
    "    # forward pass\n",
    "    Z1 = convpool(X, W1, b1)\n",
    "    Z2 = convpool(Z1, W2, b2)\n",
    "    Z3 = relu(Z2.flatten(ndim=2).dot(W3) + b3)\n",
    "    pY = T.nnet.softmax( Z3.dot(W4) + b4)\n",
    "\n",
    "    # define the cost function and prediction\n",
    "    params = (W1, b1, W2, b2, W3, b3, W4, b4)\n",
    "    reg_cost = reg*np.sum((param*param).sum() for param in params)\n",
    "    cost = -(Y * T.log(pY)).sum() + reg_cost\n",
    "    prediction = T.argmax(pY, axis=1)\n",
    "\n",
    "    # step 3: training expressions and functions\n",
    "    update_W1 = W1 + mu*dW1 - lr*T.grad(cost, W1)\n",
    "    update_b1 = b1 + mu*db1 - lr*T.grad(cost, b1)\n",
    "    update_W2 = W2 + mu*dW2 - lr*T.grad(cost, W2)\n",
    "    update_b2 = b2 + mu*db2 - lr*T.grad(cost, b2)\n",
    "    update_W3 = W3 + mu*dW3 - lr*T.grad(cost, W3)\n",
    "    update_b3 = b3 + mu*db3 - lr*T.grad(cost, b3)\n",
    "    update_W4 = W4 + mu*dW4 - lr*T.grad(cost, W4)\n",
    "    update_b4 = b4 + mu*db4 - lr*T.grad(cost, b4)\n",
    "\n",
    "    # update weight changes\n",
    "    update_dW1 = mu*dW1 - lr*T.grad(cost, W1)\n",
    "    update_db1 = mu*db1 - lr*T.grad(cost, b1)\n",
    "    update_dW2 = mu*dW2 - lr*T.grad(cost, W2)\n",
    "    update_db2 = mu*db2 - lr*T.grad(cost, b2)\n",
    "    update_dW3 = mu*dW3 - lr*T.grad(cost, W3)\n",
    "    update_db3 = mu*db3 - lr*T.grad(cost, b3)\n",
    "    update_dW4 = mu*dW4 - lr*T.grad(cost, W4)\n",
    "    update_db4 = mu*db4 - lr*T.grad(cost, b4)\n",
    "\n",
    "    train = theano.function(\n",
    "        inputs=[X, Y],\n",
    "        updates=[\n",
    "            (W1, update_W1),\n",
    "            (b1, update_b1),\n",
    "            (W2, update_W2),\n",
    "            (b2, update_b2),\n",
    "            (W3, update_W3),\n",
    "            (b3, update_b3),\n",
    "            (W4, update_W4),\n",
    "            (b4, update_b4),\n",
    "            (dW1, update_dW1),\n",
    "            (db1, update_db1),\n",
    "            (dW2, update_dW2),\n",
    "            (db2, update_db2),\n",
    "            (dW3, update_dW3),\n",
    "            (db3, update_db3),\n",
    "            (dW4, update_dW4),\n",
    "            (db4, update_db4),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # create another function for this because we want it over the whole dataset\n",
    "    get_prediction = theano.function(\n",
    "        inputs=[X, Y],\n",
    "        outputs=[cost, prediction],\n",
    "    )\n",
    "\n",
    "    t0 = datetime.now()\n",
    "    LL = []\n",
    "    for i in xrange(max_iter):\n",
    "        for j in xrange(n_batches):\n",
    "            Xbatch = Xtrain[j*batch_sz:(j*batch_sz + batch_sz),]\n",
    "            Ybatch = Ytrain_ind[j*batch_sz:(j*batch_sz + batch_sz),]\n",
    "\n",
    "            train(Xbatch, Ybatch)\n",
    "            if j % print_period == 0:\n",
    "                cost_val, prediction_val = get_prediction(Xtest, Ytest_ind)\n",
    "                err = error_rate(prediction_val, Ytest)\n",
    "                print \"Cost / err at iteration i=%d, j=%d: %.3f / %.3f\" % (i, j, cost_val, err)\n",
    "                LL.append(cost_val)\n",
    "    print \"Elapsed time:\", (datetime.now() - t0)\n",
    "    plt.plot(LL)\n",
    "    plt.show()\n",
    "\n",
    "    # visualize W1 (20, 3, 5, 5)\n",
    "    W1_val = W1.get_value()\n",
    "    grid = np.zeros((8*5, 8*5))\n",
    "    m = 0\n",
    "    n = 0\n",
    "    for i in xrange(20):\n",
    "        for j in xrange(3):\n",
    "            filt = W1_val[i,j]\n",
    "            grid[m*5:(m+1)*5,n*5:(n+1)*5] = filt\n",
    "            m += 1\n",
    "            if m >= 8:\n",
    "                m = 0\n",
    "                n += 1\n",
    "    plt.imshow(grid, cmap='gray')\n",
    "    plt.title(\"W1\")\n",
    "    plt.show()\n",
    "\n",
    "    # visualize W2 (50, 20, 5, 5)\n",
    "    W2_val = W2.get_value()\n",
    "    grid = np.zeros((32*5, 32*5))\n",
    "    m = 0\n",
    "    n = 0\n",
    "    for i in xrange(50):\n",
    "        for j in xrange(20):\n",
    "            filt = W2_val[i,j]\n",
    "            grid[m*5:(m+1)*5,n*5:(n+1)*5] = filt\n",
    "            m += 1\n",
    "            if m >= 32:\n",
    "                m = 0\n",
    "                n += 1\n",
    "    plt.imshow(grid, cmap='gray')\n",
    "    plt.title(\"W2\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
